{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptrons as Logical Operators\n",
    "\n",
    "**1. AND Operation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND operation\n",
    "weight1 = 1.0\n",
    "weight2 = 1.0\n",
    "bias = -1.2\n",
    "\n",
    "\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, False, False, True]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. OR Operation**\n",
    "\n",
    "From AND Operation to OR Operation\n",
    "\n",
    "<img src=From_AND2OR.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CASE ONE: Keep the weights still and increase the bias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR operation 1\n",
    "## keep the weights still, and increase the bias!!\n",
    "weight1 = 1.0  # keep still as in AND operation\n",
    "weight2 = 1.0  # keep still as in AND operation\n",
    "bias = -.8  # INCREASE the bias compared in AND oepration whose bias = -1.2\n",
    "\n",
    "\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, True, True, True]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CASE TWO: Keep the bias still and increase the weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      " Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "       0          0                  -1.2                    0          Yes\n",
      "       0          1                   0.0                    1          Yes\n",
      "       1          0                   0.0                    1          Yes\n",
      "       1          1                   1.2                    1          Yes\n"
     ]
    }
   ],
   "source": [
    "# OR operation\n",
    "## keep the bias still, and increase the weights!!\n",
    "weight1 = 1.2  # INCREASE the weights as in AND operation\n",
    "weight2 = 1.2  # INCREASE the weights as in AND operation\n",
    "bias = -1.2  # keep still as in AND operation\n",
    "\n",
    "\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, True, True, True]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. NOT Operation**\n",
    "\n",
    "Unlike the other perceptrons above, the `NOT` operation only cares about one input. The operation returns a `0` if the input is `1` and a `1` if it's a `0`. The other inputs to the perceptron are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      " Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "       0          0                   1.0                    1          Yes\n",
      "       0          1                  -0.1                    0          Yes\n",
      "       1          0                   0.5                    1          Yes\n",
      "       1          1                  -0.6                    0          Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = -0.5\n",
    "weight2 = -1.1\n",
    "bias = 1\n",
    "\n",
    "\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [True, False, True, False]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepFunction(t):\n",
    "    if t >= 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def prediction(X, W, b):\n",
    "    return stepFunction((np.matmul(X,W)+b)[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul([1,2],[[3],[4]])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul([1,2],[3,4])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([3,4]).reshape(-1, 1)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction([1,1],[[1],[-1]],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction([-1,1],[[1],[-1]],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80719682])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array([1,2])\n",
    "X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 5],\n",
       "       [2, 4, 6]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1,2],[3,4],[5,6]])\n",
    "X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(X.T[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Coding the Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=data_viz_coding_percAlgo.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron step works as follows. For a point with coordinates `(p,q)`, label `y`, and prediction given by the equation $\\hat{y} = step(w_1x_1 + w_2x_2 + b) $\n",
    "- If the point is correctly classified, do nothing.\n",
    "- If the point is misclassified _positive_, but it has a **negative** label, subtract $\\alpha p$, $\\alpha q$,and $\\alpha {}$ from $w_1$, $w_2$,and $b$ respectively.\n",
    "- If the point is misclassified _negative_, but it has a **positive** label, add $\\alpha p$, $\\alpha q$,and $\\alpha {}$ from $w_1$, $w_2$,and $b$ respectively. \n",
    "\n",
    "Run to graph the solution that the perceptron algorithm gives you. It'll actually draw a set of dotted lines, that show how the algorithm approaches to the best solution, given by the black solid line.\n",
    "\n",
    "These parameters may affect the solution:\n",
    "- number of epochs\n",
    "- learning rate\n",
    "- initial weights and bias\n",
    "\n",
    "Change them to see how they will affect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Setting the random seed, it can be changed to see different solutions.\n",
    "np.random.seed(40)\n",
    "\n",
    "def stepFunction(t):\n",
    "    if t >= 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def prediction(X, W, b):\n",
    "    return stepFunction((np.matmul(X,W)+b)[0])\n",
    "\n",
    "\n",
    "def perceptronStep(X, y, W, b, learn_rate = 0.01):\n",
    "    \"\"\"\n",
    "    Update weights and bias whenever needed.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "        X: a n_by_2 numpy 2D array. Each entry represents a set of coordinates. \n",
    "           It represents the 0th and 1st column in data.csv.\n",
    "           \n",
    "        y: actual labels for the datapoints. It represents the 2nd column in data.csv\n",
    "        \n",
    "        W: a 2_by_1 2D numpy array. Weights for the linear equation.\n",
    "        \n",
    "        b: Bias value for the linear equation.\n",
    "        \n",
    "        learning_rate: float. small steps in changing weights and bias when necessary.\n",
    "     \n",
    "     Returns:\n",
    "        new weights and bias.    \n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(len(X)):\n",
    "        y_hat = prediction(X[i],W,b)\n",
    "        \n",
    "        if y[i]-y_hat == 1:  # predicted neg but actually it's pos\n",
    "            W[0] += X[i][0]*learn_rate\n",
    "            W[1] += X[i][1]*learn_rate\n",
    "            b += learn_rate\n",
    "            \n",
    "        elif y[i]-y_hat == -1:  # predicted pos but actually it's neg\n",
    "            W[0] -= X[i][0]*learn_rate\n",
    "            W[1] -= X[i][1]*learn_rate\n",
    "            b -= learn_rate\n",
    "            \n",
    "    return W, b    \n",
    "\n",
    "\n",
    "def trainPerceptronAlgorithm(X, y, learn_rate = 0.001, num_epochs = 50):\n",
    "    \"\"\"\n",
    "    Runs the perceptron algorithm repeatedly on the dataset, and returns \n",
    "    a few of the boundary lines obtained in the iterations, for plotting purposes.\n",
    "    \"\"\"\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0])  # the minimum and maximun value in Variable x0 (column 0 in data.csv)\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1])  # the minimum and maximun value in Variable x1 (column 1 in data.csv)\n",
    "    \n",
    "    W = np.array(np.random.rand(2,1))  # Initialize the W weights between (0, 1)\n",
    "    b = np.random.rand(1)[0] + x_max  # Initialize the Bias b between (0, 1)\n",
    "    \n",
    "    boundary_lines = []\n",
    "    for i in range(num_epochs):\n",
    "        # In each epoch, apply the perceptron step.\n",
    "        W, b = perceptronStep(X, y, W, b, learn_rate)\n",
    "        \n",
    "        # each entry in the boundary_lines represents a linear equation.\n",
    "        boundary_lines.append((-W[0]/W[1], -b/W[1])) \n",
    "    print(boundary_lines)\n",
    "    return boundary_lines\n",
    "\n",
    "# define the graph function\n",
    "def graph_lines():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Step function to Sigmoid function\n",
    "\n",
    "sigmoid function:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\sigma(x) =  \\frac{1}{1+e^{-x}}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def linear_eq(W, X, b):\n",
    "    return np.matmul(W, X) + b\n",
    "\n",
    "\n",
    "\n",
    "def predict(W, X, b):\n",
    "    res = []\n",
    "    for entry in X:\n",
    "        linRes = linear_eq(W, entry, b)\n",
    "        sig_res = sig(linRes)\n",
    "        res.append(sig_res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([4,5])\n",
    "b = -9\n",
    "X = np.array([[-4,5],[1,1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1],\n",
       "       [ 2,  4],\n",
       "       [ 5, -5],\n",
       "       [-4,  5]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([1,1,2,4,5,-5,-4,5]).reshape((4,2))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.9999999943972036, 8.315280276641321e-07, 0.5]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(W, X, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Function\n",
    "\n",
    "Linear function scores:  \n",
    "$Z_1, Z_2, Z_3, \\dots , Z_n$, where n means number of classes,\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "P(class i) = \\frac{e^Z_i}{e^{Z_1} + e^{Z_2} + e^{Z_3} + \\dots + e^{Z_n}}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "***NOTE:*** When $n=2$, softmax funciton collpases to **sigmoid function**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09003057, 0.24472847, 0.66524096])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(L):\n",
    "    \"\"\"\n",
    "    mapping a list to softmax values.\n",
    "    \n",
    "    parameters:\n",
    "    -----------\n",
    "        L: list-like array.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "        numpy.array\n",
    "    \"\"\"\n",
    "    denominator = np.exp(L).sum()\n",
    "    numerator = np.exp(L)\n",
    "    return np.divide(numerator, denominator)\n",
    "\n",
    "softmax([5,6,7])\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross entropy\n",
    "\n",
    "Formula for cross entropy: where `y` is for the category, and `p` is for the probability.\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "Cross-Entropy = -\\sum_{i=1}^m[y_{i}ln(p_i) + (1-y_i)ln(1-p_i)]\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "<img src=cross_entropy.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(Y, P):\n",
    "    Y = np.float_(Y)\n",
    "    P = np.float_(P)\n",
    "    return -np.sum(Y*np.log(P)+(1-Y)*np.log(1-P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.115995809754082"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy([0,0,1], [.8,.7,.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Class Cross Entropy\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "ce = -\\sum_{i=1}^{n}\\sum_{j=1}^{m}y_{ij}ln(p_{ij})\n",
    "\\end{align}\n",
    "$\n",
    ", where `j` represents the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
